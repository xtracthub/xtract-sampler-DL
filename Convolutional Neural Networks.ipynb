{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jupyter Notebook Version of DL\n",
    "\n",
    "The project is first developed in Jupyter Notebook for easy testing/verification but could be moved to a formal Python Script in the future (if I have time). Contrary to the Xtract-Sampler we won't be implementing any byte extraction but rather right now assume we have the data.\n",
    "***\n",
    "Training and Developing a model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import torch, os\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from ByteVectorDataset import ByteVectorDataset\n",
    "from model import SimpleCNN\n",
    "from time import time\n",
    "\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "BYTE_BLOCK_SIZE = 512"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Files/Data Processing\n",
    "\n",
    "Mostly for testing purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading files now...\n",
      "loading files done!\n"
     ]
    }
   ],
   "source": [
    "print(\"loading files now...\")\n",
    "\n",
    "with open('CDIACFileData/ByteVectors/byte_vector_dict_512B_one_gram.pkl', \"rb\") as fp1:\n",
    "    one_gram = pickle.load(fp1)\n",
    "with open('CDIACFileData/ByteVectors/byte_vector_dict_512B_two_gram.pkl', \"rb\") as fp2:\n",
    "    two_gram = pickle.load(fp2)\n",
    "\n",
    "print(\"loading files done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_path = \"CDIACFileData/labels/cdiac_naivetruth_processed.csv\"\n",
    "dataset_one_gram = ByteVectorDataset(label_path, one_gram)\n",
    "dataset_two_gram = ByteVectorDataset(label_path, two_gram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "reccomended_num_workers = 4 * torch.cuda.device_count()\n",
    "# ^ from https://discuss.pytorch.org/t/guidelines-for-assigning-num-workers-to-dataloader/813/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader_one_gram = DataLoader(dataset_one_gram, batch_size=1,\n",
    "                        shuffle=True, num_workers=reccomended_num_workers)\n",
    "dataloader_two_gram = DataLoader(dataset_two_gram, batch_size=1,\n",
    "                        shuffle=True, num_workers=reccomended_num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [tensor([[ 60.,  63., 120., 109., 108.,  32., 118., 101., 114., 115., 105., 111.,\n",
      "         110.,  61.,  34.,  49.,  46.,  48.,  34.,  32., 101., 110.,  99., 111.,\n",
      "         100., 105., 110., 103.,  61.,  34., 117., 116., 102.,  45.,  56.,  34.,\n",
      "          63.,  62.,  13.,  10.,  60., 120.,  95., 116.,  97., 103., 115.,  62.,\n",
      "          13.,  10.,  32.,  32.,  60.,  85., 115., 101., 114.,  62.,  13.,  10.,\n",
      "          32.,  32.,  32.,  32.,  60.,  78.,  97., 109., 101.,  62.,  83., 117.,\n",
      "         108., 108., 105., 118.,  97., 110.,  44.,  32.,  75., 101., 118., 105.,\n",
      "         110.,  60.,  47.,  78.,  97., 109., 101.,  62.,  13.,  10.,  32.,  32.,\n",
      "          32.,  32.,  60.,  79., 114., 103.,  97., 110., 105., 122.,  97., 116.,\n",
      "         105., 111., 110.,  62.,  78.,  79.,  65.,  65.,  47.,  65., 116., 108.,\n",
      "          97., 110., 116., 105.,  99.,  32.,  79.,  99., 101.,  97., 110., 111.,\n",
      "         103., 114.,  97., 112., 104., 105.,  99.,  32.,  38.,  97., 109., 112.,\n",
      "          59.,  32.,  77., 101., 116., 101., 111., 114., 111., 108., 111., 103.,\n",
      "         105.,  99.,  97., 108.,  32.,  76.,  97.,  98., 111., 114.,  97., 116.,\n",
      "         111., 114., 121.,  60.,  47.,  79., 114., 103.,  97., 110., 105., 122.,\n",
      "          97., 116., 105., 111., 110.,  62.,  13.,  10.,  32.,  32.,  32.,  32.,\n",
      "          60.,  65., 100., 100., 114., 101., 115., 115.,  62.,  52.,  51.,  48.,\n",
      "          49.,  32.,  82., 105.,  99., 107., 101., 110.,  98.,  97.,  99., 107.,\n",
      "         101., 114.,  32.,  67.,  97., 117., 115., 101., 119.,  97., 121.,  60.,\n",
      "          47.,  65., 100., 100., 114., 101., 115., 115.,  62.,  13.,  10.,  32.,\n",
      "          32.,  32.,  32.,  60.,  80., 104., 111., 110., 101.,  62.,  51.,  48.,\n",
      "          53.,  45.,  51.,  54.,  49.,  45.,  52.,  51.,  56.,  50.,  60.,  47.,\n",
      "          80., 104., 111., 110., 101.,  62.,  13.,  10.,  32.,  32.,  32.,  32.,\n",
      "          60.,  69., 109.,  97., 105., 108.,  62.,  75., 101., 118., 105., 110.,\n",
      "          46.,  83., 117., 108., 108., 105., 118.,  97., 110.,  64., 110., 111.,\n",
      "          97.,  97.,  46., 103., 111., 118.,  60.,  47.,  69., 109.,  97., 105.,\n",
      "         108.,  62.,  32.,  60.,  47.,  85., 115., 101., 114.,  62.,  13.,  10.,\n",
      "          32.,  32.,  60.,  73., 110., 118., 101., 115., 116., 105., 103.,  97.,\n",
      "         116., 111., 114.,  62.,  13.,  10.,  32.,  32.,  32.,  32.,  60.,  78.,\n",
      "          97., 109., 101.,  62.,  87.,  97., 110., 110., 105., 110., 107., 104.,\n",
      "         111., 102.,  44.,  32.,  82., 105., 107.,  60.,  47.,  78.,  97., 109.,\n",
      "         101.,  62.,  13.,  10.,  32.,  32.,  32.,  32.,  60.,  79., 114., 103.,\n",
      "          97., 110., 105., 122.,  97., 116., 105., 111., 110.,  62.,  78.,  79.,\n",
      "          65.,  65.,  47.,  65.,  79.,  77.,  76.,  60.,  47.,  79., 114., 103.,\n",
      "          97., 110., 105., 122.,  97., 116., 105., 111., 110.,  62.,  13.,  10.,\n",
      "          32.,  32.,  32.,  32.,  60.,  65., 100., 100., 114., 101., 115., 115.,\n",
      "          62.,  52.,  51.,  48.,  49.,  32.,  82., 105.,  99., 107., 101., 110.,\n",
      "          98.,  97.,  99., 107., 101., 114.,  32.,  67.,  97., 117., 115., 101.,\n",
      "         119.,  97., 121.,  44.,  32.,  77., 105.,  97., 109., 105.,  32.,  70.,\n",
      "         108.,  44.,  32.,  51.,  51.,  49.,  52.,  57.,  60.,  47.,  65., 100.,\n",
      "         100., 114., 101., 115., 115.,  62.,  13.,  10.,  32.,  32.,  32.,  32.,\n",
      "          60.,  80., 104., 111., 110., 101.,  62.,  51.,  48.,  53.,  45.,  51.,\n",
      "          54.,  49.,  45.,  52.,  51.,  55.,  57.,  60.]]), tensor([3])]\n",
      "1 [tensor([[ 66.,  79.,  84.,  84.,  76.,  69.,  44.,  50.,  48.,  49.,  51.,  48.,\n",
      "          53.,  49.,  48.,  71.,  69.,  77.,  68.,  74.,  77.,  65.,  89.,  84.,\n",
      "          10.,  35.,  32.,  48.,  53.,  47.,  48.,  57.,  47.,  50.,  48.,  49.,\n",
      "          51.,  58.,  32.,  67., 104.,  97., 110., 103., 101.,  32.,  67.,  84.,\n",
      "          68.,  80.,  82.,  83.,  47.,  68.,  69.,  80.,  32., 116., 111.,  32.,\n",
      "          48.,  32.,  97., 116.,  32., 108., 105., 110., 101., 115.,  32., 111.,\n",
      "         102.,  32.,  66.,  84.,  76.,  78.,  66.,  82.,  95.,  70.,  76.,  65.,\n",
      "          71.,  95.,  87.,  32.,  61.,  32.,  53.,  46.,  10.,  35.,  32.,  48.,\n",
      "          53.,  47.,  48.,  57.,  47.,  50.,  48.,  49.,  51.,  58.,  32.,  67.,\n",
      "         111., 114., 114., 101.,  99., 116.,  32., 116., 104., 101.,  32., 101.,\n",
      "         114., 114., 111., 114.,  32., 111., 102.,  32.,  99., 111., 110., 118.,\n",
      "         101., 114., 116., 101., 100.,  32., 116., 105., 109., 101.,  32., 102.,\n",
      "         114., 111., 109.,  32.,  74.,  83.,  84.,  32., 116., 111.,  32.,  71.,\n",
      "          77.,  84.,  46.,  10.,  35.,  66.,  79.,  84.,  84.,  76.,  69.,  44.,\n",
      "          50.,  48.,  49.,  50.,  49.,  50.,  48.,  54.,  77.,  73.,  82.,  67.,\n",
      "          74.,  72.,  65.,  84.,  83.,  10.,  35.,  32.,  49.,  50.,  47.,  48.,\n",
      "          54.,  47.,  50.,  48.,  49.,  50.,  32.,  58.,  32.,  67., 104.,  97.,\n",
      "         110., 103., 101.,  32.,  66.,  84.,  76.,  78.,  66.,  82.,  95.,  70.,\n",
      "          76.,  65.,  71.,  95.,  87.,  58.,  32.,  56.,  32., 116., 111.,  32.,\n",
      "          53.,  32.,  97., 116.,  32., 108., 105., 110., 101., 115.,  32., 111.,\n",
      "         102.,  32.,  66.,  84.,  76.,  78.,  66.,  82.,  32.,  61.,  32.,  45.,\n",
      "          57.,  46.,  10.,  35.,  32.,  48.,  50.,  47.,  49.,  57.,  47.,  50.,\n",
      "          48.,  48.,  57.,  32.,  58.,  32., 112.,  72.,  32., 115.,  99.,  97.,\n",
      "         108., 101.,  32., 115., 112., 101.,  99., 105., 102., 105., 101., 100.,\n",
      "          32., 105., 110.,  32., 104., 101.,  97., 100., 101., 114.,  46.,  10.,\n",
      "          35.,  32.,  48.,  50.,  47.,  49.,  57.,  47.,  50.,  48.,  48.,  57.,\n",
      "          32.,  58.,  32.,  78.,  79.,  50.,  43.,  78.,  79.,  51.,  32., 108.,\n",
      "          97.,  98., 101., 108.,  32.,  99., 111., 114., 114., 101.,  99., 116.,\n",
      "         101., 100.,  32., 105., 110.,  32., 104., 101.,  97., 100., 101., 114.,\n",
      "          46.,  10.,  35.,  32.,  48.,  52.,  47.,  48.,  53.,  47.,  50.,  48.,\n",
      "          49.,  48.,  32.,  58.,  32., 112.,  72.,  32., 115.,  99.,  97., 108.,\n",
      "         101.,  32., 115., 112., 101.,  99., 105., 102., 105., 101., 100.,  32.,\n",
      "         105., 110.,  32., 104., 101.,  97., 100., 101., 114.,  44.,  32.,  99.,\n",
      "         111., 114., 114., 101.,  99., 116., 101., 100.,  32., 102., 111., 114.,\n",
      "          32.,  81.,  70.,  32., 111., 102.,  32.,  67.,  84.,  68.,  83.,  65.,\n",
      "          76.,  32.,  40.,  53.,  32.,  45.,  62.,  32.,  50.,  41.,  44.,  32.,\n",
      "          99., 111., 110., 118., 101., 114., 116., 101., 100.,  32., 116., 105.,\n",
      "         109., 101.,  32., 102., 114., 111., 109.,  32.,  74.,  83.,  84.,  32.,\n",
      "         116., 111.,  32.,  71.,  77.,  84.,  10.,  69.,  88.,  80.,  79.,  67.,\n",
      "          79.,  68.,  69.,  44.,  83.,  69.,  67.,  84.,  95.,  73.,  68.,  44.,\n",
      "          83.,  84.,  78.,  78.,  66.,  82.,  44.,  67.,  65.,  83.,  84.,  78.,\n",
      "          79.,  44.,  83.,  65.,  77.,  80.,  78.,  79.,  44.,  66.,  84.,  76.,\n",
      "          78.,  66.,  82.,  44.,  66.,  84.,  76.,  78.]]), tensor([2])]\n",
      "2 [tensor([[ 80., 108., 101.,  97., 115., 101.,  32.,  99., 105., 116., 101.,  32.,\n",
      "         116., 104., 105., 115.,  32., 100.,  97., 116.,  97.,  32., 115., 101.,\n",
      "         116.,  32.,  97., 115.,  58.,  10.,  10.,  83., 117., 116., 116., 111.,\n",
      "         110.,  44.,  32.,  65.,  46.,  44.,  32.,  67.,  46.,  32.,  83.,  97.,\n",
      "          98., 105., 110., 101.,  44.,  32.,  65.,  46.,  32.,  65., 110., 100.,\n",
      "         101., 114., 115., 115., 111., 110.,  44.,  32.,  78.,  46.,  32.,  66.,\n",
      "          97., 116., 101., 115.,  44.,  32.,  83.,  46.,  32.,  77., 117., 115.,\n",
      "         105., 101., 108., 101., 119., 105.,  99., 122.,  44.,  32.,  83.,  46.,\n",
      "          32.,  77.,  97., 101., 110., 110., 101., 114.,  44.,  32.,  67.,  46.,\n",
      "          32.,  68., 105., 101., 116., 114., 105.,  99., 104.,  44.,  32.,  82.,\n",
      "          46.,  32.,  66., 111., 116., 116.,  44.,  32.,  97., 110., 100.,  32.,\n",
      "          10.,  74.,  46.,  32.,  79., 115.,  98., 111., 114., 110., 101.,  46.,\n",
      "          32.,  50.,  48.,  49.,  52.,  46.,  32.,  72., 105., 103., 104.,  45.,\n",
      "         114., 101., 115., 111., 108., 117., 116., 105., 111., 110.,  32., 111.,\n",
      "          99., 101.,  97., 110.,  32.,  97., 110., 100.,  32.,  97., 116., 109.,\n",
      "         111., 115., 112., 104., 101., 114., 101.,  32., 112.,  67.,  79.,  50.,\n",
      "          32., 116., 105., 109., 101.,  45., 115., 101., 114., 105., 101., 115.,\n",
      "          32., 109., 101.,  97., 115., 117., 114., 101., 109., 101., 110., 116.,\n",
      "         115.,  32., 102., 114., 111., 109.,  32., 109., 111., 111., 114., 105.,\n",
      "         110., 103.,  32.,  10.,  67., 114., 101., 115.,  99., 101., 110., 116.,\n",
      "          95.,  54.,  52.,  87.,  95.,  51.,  50.,  78.,  46.,  32., 104., 116.,\n",
      "         116., 112.,  58.,  47.,  47.,  99., 100., 105.,  97.,  99.,  46., 101.,\n",
      "         115., 100.,  46., 111., 114., 110., 108.,  46., 103., 111., 118.,  47.,\n",
      "         102., 116., 112.,  47., 111.,  99., 101.,  97., 110., 115.,  47.,  77.,\n",
      "         111., 111., 114., 105., 110., 103., 115.,  47.,  67., 114., 101., 115.,\n",
      "          99., 101., 110., 116.,  95.,  54.,  52.,  87.,  95.,  51.,  50.,  78.,\n",
      "          47.,  46.,  32.,  67.,  97., 114.,  98., 111., 110.,  32.,  68., 105.,\n",
      "         111., 120., 105., 100., 101.,  32.,  10.,  73., 110., 102., 111., 114.,\n",
      "         109.,  97., 116., 105., 111., 110.,  32.,  65., 110.,  97., 108., 121.,\n",
      "         115., 105., 115.,  32.,  67., 101., 110., 116., 101., 114.,  44.,  32.,\n",
      "          79.,  97., 107.,  32.,  82., 105., 100., 103., 101.,  32.,  78.,  97.,\n",
      "         116., 105., 111., 110.,  97., 108.,  32.,  76.,  97.,  98., 111., 114.,\n",
      "          97., 116., 111., 114., 121.,  44.,  32.,  85.,  83.,  32.,  68., 101.,\n",
      "         112.,  97., 114., 116., 109., 101., 110., 116.,  32., 111., 102.,  32.,\n",
      "          69., 110., 101., 114., 103., 121.,  44.,  32.,  79.,  97., 107.,  32.,\n",
      "          82., 105., 100., 103., 101.,  44.,  32.,  10.,  84., 101., 110., 110.,\n",
      "         101., 115., 115., 101., 101.,  46.,  32., 100., 111., 105.,  58.,  32.,\n",
      "          49.,  48.,  46.,  51.,  51.,  51.,  52.,  47.,  67.,  68.,  73.,  65.,\n",
      "          67.,  47.,  79.,  84.,  71.,  46.,  84.,  83.,  77.,  95.,  67., 114.,\n",
      "         101., 115.,  99., 101., 110., 116.,  95.,  54.,  52.,  87.,  95.,  51.,\n",
      "          50.,  78.,  10.,  10.,  67., 111., 108., 117., 109., 110.,  32.,  49.,\n",
      "          32.,  45.,  32.,  77., 111., 111., 114., 105., 110., 103.,  32., 110.,\n",
      "          97., 109., 101.,  32.,  10.,  67., 111., 108.]]), tensor([1])]\n"
     ]
    }
   ],
   "source": [
    "for i_batch, sample_batched in enumerate(dataloader_one_gram):\n",
    "    print(i_batch, sample_batched)\n",
    "    # observe 3rd batch and stop.\n",
    "    if i_batch == 2:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From here on out we will just be using one grams but the two grams process is identical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11474\n",
      "2869\n"
     ]
    }
   ],
   "source": [
    "TRAIN_TEST_SPLIT = .8 # 80% for training 20% for testing\n",
    "train_set_size = int(TRAIN_TEST_SPLIT * len(dataset_one_gram))\n",
    "val_set_size = len(dataset_one_gram) - train_set_size\n",
    "train_set, val_set = torch.utils.data.random_split(dataset_one_gram, [train_set_size, val_set_size])\n",
    "print(len(train_set))\n",
    "print(len(val_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_set, batch_size=32,\n",
    "                        shuffle=True, num_workers=reccomended_num_workers)\n",
    "val_loader = DataLoader(val_set, batch_size=32,\n",
    "                        shuffle=True, num_workers=reccomended_num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "torch.Size([32, 512])\n",
      "tensor([1, 1, 3, 1, 1, 3, 5, 3, 1, 2, 1, 0, 2, 0, 2, 2, 0, 2, 1, 1, 2, 2, 3, 1,\n",
      "        1, 2, 1, 1, 3, 2, 2, 2])\n"
     ]
    }
   ],
   "source": [
    "dataiter = iter(train_loader)\n",
    "images, labels = dataiter.next()\n",
    "print(type(images))\n",
    "print(images.shape)\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "0\n",
      "<torch.cuda.device object at 0x7fc9c0b11df0>\n",
      "4\n",
      "Tesla V100-SXM2-32GB\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.current_device())\n",
    "print(torch.cuda.device(1))\n",
    "print(torch.cuda.device_count())\n",
    "print(torch.cuda.get_device_name(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.2\n"
     ]
    }
   ],
   "source": [
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "torch.rand(1).cuda()\n",
    "print(torch.version.cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's use 4 GPUs!\n"
     ]
    }
   ],
   "source": [
    "%autoreload 2\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = SimpleCNN(BYTE_BLOCK_SIZE)\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "    model = nn.DataParallel(model, device_ids=[0])\n",
    "model.to(device)\n",
    "\n",
    "loss_function = nn.NLLLoss() # This is a convex loss function\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=.03) # From my CS361 class SGD is shown to do well on convex functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 - Training loss: -524059800019.64136\n",
      "Epoch 1 - Training loss: -9401254744896.89\n",
      "Epoch 2 - Training loss: -40934368018249.445\n",
      "Epoch 3 - Training loss: -105912079956053.58\n",
      "Epoch 4 - Training loss: -211838474312244.78\n",
      "Epoch 5 - Training loss: -363878928988701.94\n",
      "Epoch 6 - Training loss: -565353263723123.5\n",
      "Epoch 7 - Training loss: -819143398112869.2\n",
      "Epoch 8 - Training loss: -1128076303755840.2\n",
      "Epoch 9 - Training loss: -1494795087748869.0\n",
      "\n",
      "Training Time (in minutes) =  0.33757022619247434\n"
     ]
    }
   ],
   "source": [
    "%autoreload 2\n",
    "time0 = time()\n",
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "    running_loss = 0\n",
    "    for byte_vector, labels in train_loader:\n",
    "        #print(byte_vector.shape)\n",
    "        byte_vector = byte_vector.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        #Training Pass\n",
    "        optimizer.zero_grad()\n",
    "       \n",
    "        output = model(byte_vector).to(device)\n",
    "        #print(\"Outside: input size\", input.size(), \"output_size\", output.size())\n",
    "        #print(output.shape)\n",
    "        loss = loss_function(output, labels)\n",
    "        \n",
    "        #backpropagation\n",
    "        loss.backward()\n",
    "        \n",
    "        #optimization\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    else:\n",
    "        print(\"Epoch {} - Training loss: {}\".format(epoch, running_loss/len(train_loader)))\n",
    "\n",
    "\n",
    "print(\"\\nTraining Time (in minutes) = \", (time()-time0)/60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Images Tested = 2869\n",
      "\n",
      "Model Accuracy = 0.04879749041477867\n"
     ]
    }
   ],
   "source": [
    "correct_count = 0\n",
    "all_count = 0\n",
    "for byte_vector, labels in val_loader:\n",
    "    for i in range(len(labels)):\n",
    "        byte_vector.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output = model(byte_vector)\n",
    "\n",
    "        probabilities = torch.exp(output)\n",
    "        probab = list(probabilities.cpu().numpy()[0])\n",
    "        pred_label = probab.index(max(probab))\n",
    "        true_label = labels.cpu().numpy()[i]\n",
    "        if true_label == pred_label:\n",
    "            correct_count += 1\n",
    "        all_count += 1\n",
    "\n",
    "print(\"Number of Images Tested =\", all_count)\n",
    "print(\"\\nModel Accuracy =\", (correct_count/all_count))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
