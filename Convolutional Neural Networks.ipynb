{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jupyter Notebook Version of DL\n",
    "\n",
    "The project is first developed in Jupyter Notebook for easy testing/verification but could be moved to a formal Python Script in the future (if I have time). Contrary to the Xtract-Sampler we won't be implementing any byte extraction but rather right now assume we have the data.\n",
    "***\n",
    "Training and Developing a model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import torch, os\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from ByteVectorDataset import ByteVectorDataset\n",
    "from model import SimpleCNN\n",
    "from time import time\n",
    "\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BYTE_BLOCK_SIZE = 512"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Files/Data Processing\n",
    "\n",
    "Mostly for testing purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading files now...\n",
      "loading files done!\n"
     ]
    }
   ],
   "source": [
    "print(\"loading files now...\")\n",
    "\n",
    "with open('CDIACFileData/ByteVectors/byte_vector_dict_512B_one_gram.pkl', \"rb\") as fp1:\n",
    "    one_gram = pickle.load(fp1)\n",
    "with open('CDIACFileData/ByteVectors/byte_vector_dict_512B_two_gram.pkl', \"rb\") as fp2:\n",
    "    two_gram = pickle.load(fp2)\n",
    "\n",
    "print(\"loading files done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_path = \"CDIACFileData/labels/cdiac_naivetruth_processed.csv\"\n",
    "dataset_one_gram = ByteVectorDataset(label_path, one_gram)\n",
    "dataset_two_gram = ByteVectorDataset(label_path, two_gram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "reccomended_num_workers = 4 * torch.cuda.device_count()\n",
    "# ^ from https://discuss.pytorch.org/t/guidelines-for-assigning-num-workers-to-dataloader/813/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader_one_gram = DataLoader(dataset_one_gram, batch_size=1,\n",
    "                        shuffle=True, num_workers=reccomended_num_workers)\n",
    "dataloader_two_gram = DataLoader(dataset_two_gram, batch_size=1,\n",
    "                        shuffle=True, num_workers=reccomended_num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [tensor([[67, 82, 85, 73, 83, 69, 44, 68, 65, 84, 69, 44, 84, 73, 77, 69, 44, 76,\n",
      "         65, 84, 73, 84, 85, 68, 69, 44, 76, 79, 78, 71, 73, 84, 85, 68, 69, 44,\n",
      "         65, 73, 82, 95, 84, 77, 80, 44, 72, 85, 77, 73, 68, 73, 84, 89, 44, 83,\n",
      "         79, 76, 65, 82, 95, 82, 65, 68, 44, 82, 69, 76, 95, 87, 73, 78, 68, 95,\n",
      "         83, 80, 69, 69, 68, 44, 83, 72, 73, 80, 95, 83, 80, 69, 69, 68, 44, 65,\n",
      "         66, 83, 79, 76, 85, 84, 69, 95, 87, 73, 78, 68, 95, 83, 80, 69, 69, 68,\n",
      "         44, 65, 84, 77, 95, 80, 82, 69, 44, 88, 67, 79, 50, 95, 65, 73, 82, 44,\n",
      "         83, 68, 44, 88, 67, 79, 50, 95, 65, 73, 82, 95, 70, 76, 65, 71, 44, 70,\n",
      "         67, 79, 50, 95, 65, 73, 82, 44, 83, 68, 44, 65, 73, 82, 95, 70, 67, 79,\n",
      "         50, 95, 70, 76, 65, 71, 44, 80, 67, 79, 50, 95, 65, 73, 82, 44, 83, 68,\n",
      "         44, 80, 67, 79, 50, 95, 65, 73, 82, 95, 70, 76, 65, 71, 44, 69, 81, 95,\n",
      "         84, 77, 80, 44, 83, 83, 84, 44, 83, 68, 44, 88, 67, 79, 50, 95, 69, 81,\n",
      "         44, 83, 68, 44, 70, 67, 79, 50, 95, 69, 81, 44, 83, 68, 44, 70, 67, 79,\n",
      "         50, 95, 83, 83, 84, 44, 83, 68, 44, 88, 67, 79, 50, 95, 83, 83, 84, 44,\n",
      "         83, 68, 44, 80, 67, 79, 50, 95, 83, 83, 84, 44, 83, 68, 44, 68, 69, 76,\n",
      "         95, 70, 67, 79, 50, 44, 68, 69, 76, 95, 88, 67, 79, 50, 44, 68, 69, 76,\n",
      "         95, 80, 67, 79, 50, 44, 83, 83, 83, 44, 83, 68, 44, 69, 81, 95, 80, 82,\n",
      "         69, 13, 44, 89, 89, 89, 89, 77, 77, 68, 68, 44, 72, 72, 77, 77, 83, 83,\n",
      "         44, 44, 44, 68, 69, 71, 95, 67, 44, 37, 44, 87, 47, 77, 50, 44, 77, 47,\n",
      "         83, 44, 75, 78, 44, 77, 47, 83, 44, 72, 80, 65, 44, 80, 80, 77, 44, 44,\n",
      "         57, 44, 85, 65, 84, 77, 44, 57, 44, 57, 44, 85, 65, 84, 77, 44, 57, 44,\n",
      "         57, 44, 68, 69, 71, 95, 67, 44, 68, 69, 71, 95, 67, 44, 44, 80, 80, 77,\n",
      "         44, 44, 85, 65, 84, 77, 44, 44, 85, 65, 84, 77, 44, 44, 80, 80, 77, 44,\n",
      "         44, 85, 65, 84, 77, 44, 44, 85, 65, 84, 77, 44, 80, 80, 77, 44, 85, 65,\n",
      "         84, 77, 44, 44, 44, 72, 80, 65, 13, 80, 88, 49, 51, 55, 69, 44, 50, 48,\n",
      "         49, 48, 48, 56, 48, 55, 44, 56, 50, 48, 48, 48, 44, 51, 52, 46, 55, 49,\n",
      "         57, 57, 56, 51, 44, 49, 51, 55, 46, 51, 48, 49, 53, 56, 50, 44, 50, 55,\n",
      "         46, 54, 52, 44, 53, 52, 44, 48, 46, 50, 49, 44, 54, 46, 56, 44, 48, 46,\n",
      "         53, 44, 48, 46, 51, 44, 49, 48]], dtype=torch.uint8), tensor([2])]\n",
      "1 [tensor([[ 71,  82,  79,  85,  80,  47,  83,  72,  73,  80,  44,  67,  82,  85,\n",
      "          73,  83,  69,  95,  68,  69,  83,  73,  71,  78,  65,  84,  73,  79,\n",
      "          78,  44,  74,  68,  95,  71,  77,  84,  44,  68,  65,  84,  69,  95,\n",
      "          77,  77,  47,  68,  68,  47,  89,  89,  89,  89,  44,  68,  65,  84,\n",
      "          69,  95,  68,  68,  77,  77,  89,  89,  89,  89,  44,  84,  73,  77,\n",
      "          69,  95,  72,  72,  58,  77,  77,  58,  83,  83,  44,  76,  65,  84,\n",
      "          95,  68,  69,  67,  95,  68,  69,  71,  82,  69,  69,  44,  76,  79,\n",
      "          78,  71,  95,  68,  69,  67,  95,  68,  69,  71,  82,  69,  69,  44,\n",
      "         120,  67,  79,  50,  87,  95,  80,  80,  77,  44, 120,  67,  79,  50,\n",
      "          65,  95,  80,  80,  77,  44, 120,  67,  79,  50,  65,  95,  73,  78,\n",
      "          84,  69,  82,  80,  79,  76,  65,  84,  69,  68,  95,  80,  80,  77,\n",
      "          44,  80,  82,  69,  83,  95,  69,  81,  85,  73,  76,  95, 104,  80,\n",
      "          97,  44,  80,  82,  69,  83,  95,  83,  69,  65,  76,  69,  86,  69,\n",
      "          76,  95, 104,  80,  97,  44,  69, 113,  84,  69,  77,  80,  95,  67,\n",
      "          44,  83,  83,  84,  40,  84,  83,  71,  41,  95,  67,  44,  83,  65,\n",
      "          76,  40,  84,  83,  71,  41,  95,  80,  69,  82,  77,  73,  76,  44,\n",
      "         102,  67,  79,  50,  87,  64,  83,  83,  84,  95, 117,  65,  84,  77,\n",
      "          44, 102,  67,  79,  50,  65,  95, 117,  65,  84,  77,  44, 100, 102,\n",
      "          67,  79,  50,  95, 117,  65,  84,  77,  44,  81,  67,  95,  70,  76,\n",
      "          65,  71,  13,  10,  80,  77,  69,  76,  47,  79,  79,  67,  76,  95,\n",
      "          84, 105,  97, 110, 106, 105, 110,  44,  84, 105,  97, 110,  95,  50,\n",
      "          48,  48,  57,  95,  48,  51,  44,  57,  48,  46,  48,  49,  50,  49,\n",
      "          53,  50,  55,  56,  44,  51,  47,  51,  49,  47,  50,  48,  48,  57,\n",
      "          44,  51,  49,  48,  51,  50,  48,  48,  57,  44,  48,  58,  49,  53,\n",
      "          58,  50,  50,  44,  50,  53,  46,  57,  54,  52,  51,  44,  49,  50,\n",
      "          49,  46,  57,  54,  48,  54,  44,  45,  57,  57,  57,  44,  51,  57,\n",
      "          53,  46,  50,  51,  57,  53,  57,  56,  54,  44,  45,  57,  57,  57,\n",
      "          44,  49,  48,  50,  50,  46,  48,  50,  44,  49,  48,  49,  54,  46,\n",
      "          49,  57,  44,  49,  57,  46,  55,  56,  44,  49,  57,  46,  48,  57,\n",
      "          49,  44,  51,  51,  46,  56,  56,  57,  44,  45,  57,  57,  57,  44,\n",
      "          45,  57,  57,  57,  44,  45,  57,  57,  57,  44,  57,  13,  10,  80,\n",
      "          77,  69,  76,  47,  79,  79,  67,  76,  95,  84, 105,  97, 110, 106,\n",
      "         105, 110,  44,  84, 105,  97, 110,  95,  50,  48,  48,  57,  95,  48,\n",
      "          51,  44,  57,  48,  46,  48,  49,  51,  50,  56,  55,  48,  52,  44,\n",
      "          51,  47,  51,  49,  47,  50,  48,  48,  57,  44,  51,  49,  48,  51,\n",
      "          50,  48,  48,  57,  44,  48,  58,  49,  55,  58,  53,  57,  44,  50,\n",
      "          53,  46,  57,  55,  52,  54,  44,  49]], dtype=torch.uint8), tensor([2])]\n",
      "2 [tensor([[ 80, 108, 101,  97, 115, 101,  32,  99, 105, 116, 101,  32, 116, 104,\n",
      "         105, 115,  32, 100,  97, 116,  97,  32, 115, 101, 116,  32,  97, 115,\n",
      "          58,  10,  10, 118,  97, 110,  32,  71, 101, 101, 110,  44,  32,  65,\n",
      "          46,  44,  32,  87,  46,  32,  83, 109, 101, 116, 104, 105, 101,  32,\n",
      "          97, 110, 100,  32,  68,  46,  32,  83, 105, 103, 109,  97, 110,  46,\n",
      "          32,  50,  48,  49,  52,  46,  32,  72, 121, 100, 114, 111, 103, 114,\n",
      "          97, 112, 104, 105,  99,  32,  97, 110, 100,  32,  67, 104, 101, 109,\n",
      "         105,  99,  97, 108,  32, 100,  97, 116,  97,  32, 111,  98, 116,  97,\n",
      "         105, 110, 101, 100,  32, 100, 117, 114, 105, 110, 103,  32, 116, 104,\n",
      "         101,  32,  82,  47,  86,  32,  77, 101, 108, 118, 105, 108, 108, 101,\n",
      "          32,  32,  10,  79,  88,  77,  90,  48,  49,  77,  86,  32,  67, 114,\n",
      "         117, 105, 115, 101,  32, 105, 110,  32,  49,  57,  57,  57,  46,  32,\n",
      "         104, 116, 116, 112,  58,  47,  47,  99, 100, 105,  97,  99,  46, 111,\n",
      "         114, 110, 108,  46, 103, 111, 118,  47, 102, 116, 112,  47, 111,  99,\n",
      "         101,  97, 110, 115,  47,  71,  76,  79,  68,  65,  80, 118,  50,  47,\n",
      "          51,  49,  56,  77,  49,  57,  57,  57,  49,  48,  50,  57,  46,  32,\n",
      "          67,  97, 114,  98, 111, 110,  32,  68, 105, 111, 120, 105, 100, 101,\n",
      "          32,  73, 110, 102, 111, 114, 109,  97, 116, 105, 111, 110,  32,  10,\n",
      "          65, 110,  97, 108, 121, 115, 105, 115,  32,  67, 101, 110, 116, 101,\n",
      "         114,  44,  32,  79,  97, 107,  32,  82, 105, 100, 103, 101,  32,  78,\n",
      "          97, 116, 105, 111, 110,  97, 108,  32,  76,  97,  98, 111, 114,  97,\n",
      "         116, 111, 114, 121,  44,  32,  85,  83,  32,  68, 101, 112,  97, 114,\n",
      "         116, 109, 101, 110, 116,  32, 111, 102,  32,  69, 110, 101, 114, 103,\n",
      "         121,  44,  32,  79,  97, 107,  32,  82, 105, 100, 103, 101,  44,  32,\n",
      "          84, 101, 110, 110, 101, 115, 115, 101, 101,  46,  32,  10, 100, 111,\n",
      "         105,  58,  32,  49,  48,  46,  51,  51,  51,  52,  47,  67,  68,  73,\n",
      "          65,  67,  47,  79,  84,  71,  46,  51,  49,  56,  77,  49,  57,  57,\n",
      "          57,  49,  48,  50,  57,  10,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0,   0,   0,   0,   0,   0,   0]], dtype=torch.uint8), tensor([1])]\n",
      "3 [tensor([[10, 69, 88, 80, 79, 67, 79, 68, 69,  9, 67, 82, 85, 73, 83, 69,  9, 68,\n",
      "         65, 84, 69, 32, 91, 77, 77, 47, 68, 68, 47, 89, 89, 89, 89, 93,  9, 84,\n",
      "         73, 77, 69, 32, 91, 72, 72, 47, 77, 77, 93,  9, 76, 65, 84, 73, 84, 85,\n",
      "         68, 69,  9, 76, 79, 78, 71, 73, 84, 85, 68, 69,  9, 88, 67, 79, 50, 95,\n",
      "         65, 73, 82, 32, 91, 85, 77, 79, 76, 47, 77, 79, 76, 93,  9, 88, 67, 79,\n",
      "         50, 95, 65, 73, 82, 95, 70, 76, 65, 71,  9, 88, 67, 79, 50, 95, 69, 81,\n",
      "         32, 91, 85, 77, 79, 76, 47, 77, 79, 76, 93,  9, 88, 67, 79, 50, 95, 69,\n",
      "         81, 95, 70, 76, 65, 71,  9, 65, 84, 77, 95, 80, 82, 69, 32, 91, 72, 80,\n",
      "         65, 93,  9, 65, 84, 77, 95, 80, 82, 69, 95, 70, 76, 65, 71,  9, 69, 81,\n",
      "         95, 84, 77, 80, 32, 91, 68, 69, 71, 95, 67, 93,  9, 69, 81, 95, 84, 77,\n",
      "         80, 95, 70, 76, 65, 71,  9, 83, 83, 84, 32, 91, 68, 69, 71, 95, 67, 93,\n",
      "          9, 83, 83, 84, 95, 70, 76, 65, 71,  9, 83, 83, 83,  9, 83, 83, 83, 95,\n",
      "         70, 76, 65, 71, 10, 52, 57, 85, 70, 50, 48, 48, 57, 48, 49, 49, 54,  9,\n",
      "         75, 83, 48, 57, 48, 49,  9, 49, 47, 49, 54, 47, 48, 57,  9, 56, 58, 51,\n",
      "         53,  9, 51, 52, 46, 48, 49,  9, 49, 51, 52, 46, 57, 55,  9, 51, 57, 50,\n",
      "         46, 50,  9, 50,  9, 45, 57, 57, 57,  9, 52,  9, 49, 48, 50, 54, 46, 49,\n",
      "          9, 50,  9, 49, 53, 46, 54,  9, 50,  9, 49, 51, 46, 53,  9, 50,  9, 51,\n",
      "         51, 46, 53, 51,  9, 50, 10, 52, 57, 85, 70, 50, 48, 48, 57, 48, 49, 49,\n",
      "         54,  9, 75, 83, 48, 57, 48, 49,  9, 49, 47, 49, 54, 47, 48, 57,  9, 56,\n",
      "         58, 52, 56,  9, 51, 51, 46, 57, 54,  9, 49, 51, 52, 46, 57, 55,  9, 45,\n",
      "         57, 57, 57,  9, 52,  9, 51, 51, 51, 46, 57,  9, 50,  9, 49, 48, 50, 53,\n",
      "         46, 57,  9, 50,  9, 49, 53, 46, 56,  9, 50,  9, 49, 52, 46, 52,  9, 50,\n",
      "          9, 51, 51, 46, 53, 51,  9, 50, 10, 52, 57, 85, 70, 50, 48, 48, 57, 48,\n",
      "         49, 49, 54,  9, 75, 83, 48, 57, 48, 49,  9, 49, 47, 49, 54, 47, 48, 57,\n",
      "          9, 56, 58, 53, 51,  9, 51, 51, 46, 57, 52,  9, 49, 51, 52, 46, 57, 55,\n",
      "          9, 51, 57, 49, 46, 55,  9, 50,  9, 45, 57, 57, 57,  9, 52,  9, 49, 48,\n",
      "         50, 54,  9, 50,  9, 49, 53, 46, 56,  9, 50,  9, 49, 52, 46, 51,  9, 50,\n",
      "          9, 51, 51, 46, 55, 54,  9, 50, 10, 52, 57, 85, 70, 50, 48, 48, 57, 48,\n",
      "         49, 49, 54,  9, 75, 83, 48, 57]], dtype=torch.uint8), tensor([2])]\n"
     ]
    }
   ],
   "source": [
    "for i_batch, sample_batched in enumerate(dataloader_one_gram):\n",
    "    print(i_batch, sample_batched)\n",
    "    # observe 3rd batch and stop.\n",
    "    if i_batch == 2:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From here on out we will just be using one grams but the two grams process is identical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11474\n",
      "2869\n"
     ]
    }
   ],
   "source": [
    "TRAIN_TEST_SPLIT = .8 # 80% for training 20% for testing\n",
    "train_set_size = int(TRAIN_TEST_SPLIT * len(dataset_one_gram))\n",
    "val_set_size = len(dataset_one_gram) - train_set_size\n",
    "train_set, val_set = torch.utils.data.random_split(dataset_one_gram, [train_set_size, val_set_size])\n",
    "print(len(train_set))\n",
    "print(len(val_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_set, batch_size=32,\n",
    "                        shuffle=True, num_workers=reccomended_num_workers)\n",
    "val_loader = DataLoader(val_set, batch_size=32,\n",
    "                        shuffle=True, num_workers=reccomended_num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "torch.Size([32, 512])\n",
      "tensor([5, 1, 0, 2, 2, 1, 1, 2, 2, 2, 2, 3, 4, 2, 3, 2, 3, 3, 2, 3, 1, 2, 4, 1,\n",
      "        1, 2, 2, 0, 2, 1, 2, 2])\n"
     ]
    }
   ],
   "source": [
    "dataiter = iter(train_loader)\n",
    "images, labels = dataiter.next()\n",
    "print(type(images))\n",
    "print(images.shape)\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "0\n",
      "<torch.cuda.device object at 0x7f4ec87aaa00>\n",
      "4\n",
      "Tesla V100-SXM2-32GB\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.current_device())\n",
    "print(torch.cuda.device(1))\n",
    "print(torch.cuda.device_count())\n",
    "print(torch.cuda.get_device_name(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-96-cab376caa331>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'CUDA_LAUNCH_BLOCKING'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"1\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1."
     ]
    }
   ],
   "source": [
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "torch.rand(1).cuda()\n",
    "print(torch.version.cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's use 4 GPUs!\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-86-3548497e2569>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Let's use\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"GPUs!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataParallel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mloss_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNLLLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# This is a convex loss function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    850\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    851\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 852\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    853\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m     def register_backward_hook(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    528\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    531\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    528\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    531\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    528\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    531\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    550\u001b[0m                 \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 552\u001b[0;31m                     \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    553\u001b[0m                 \u001b[0mshould_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    848\u001b[0m                 return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None,\n\u001b[1;32m    849\u001b[0m                             non_blocking, memory_format=convert_to_format)\n\u001b[0;32m--> 850\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    851\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    852\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1."
     ]
    }
   ],
   "source": [
    "%autoreload 2\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = SimpleCNN(BYTE_BLOCK_SIZE)\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "    model = nn.DataParallel(model)\n",
    "model.to(device)\n",
    "\n",
    "loss_function = nn.NLLLoss() # This is a convex loss function\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=.03) # From my CS361 class SGD is shown to do well on convex functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 - Training loss: -7.695251252631387e+16\n",
      "Epoch 1 - Training loss: -8.12736058212467e+16\n",
      "Epoch 2 - Training loss: -8.574409860843882e+16\n",
      "Epoch 3 - Training loss: -9.036789000037315e+16\n",
      "Epoch 4 - Training loss: -9.512069710138062e+16\n",
      "Epoch 5 - Training loss: -1.0003913434016786e+17\n",
      "Epoch 6 - Training loss: -1.0515376202414504e+17\n",
      "Epoch 7 - Training loss: -1.1038894388896542e+17\n",
      "Epoch 8 - Training loss: -1.1582011860655275e+17\n",
      "Epoch 9 - Training loss: -1.2135831933902405e+17\n",
      "\n",
      "Training Time (in minutes) =  0.3542299469312032\n"
     ]
    }
   ],
   "source": [
    "%autoreload 2\n",
    "time0 = time()\n",
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "    running_loss = 0\n",
    "    for byte_vector, labels in train_loader:\n",
    "        #print(byte_vector.shape)\n",
    "        \n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        #Training Pass\n",
    "        optimizer.zero_grad()\n",
    "       \n",
    "        output = model(byte_vector).to(device)\n",
    "        #print(output.shape)\n",
    "        loss = loss_function(output, labels)\n",
    "        \n",
    "        #backpropagation\n",
    "        loss.backward()\n",
    "        \n",
    "        #optimization\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    else:\n",
    "        print(\"Epoch {} - Training loss: {}\".format(epoch, running_loss/len(train_loader)))\n",
    "\n",
    "\n",
    "print(\"\\nTraining Time (in minutes) = \", (time()-time0)/60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_count, all_count = 0\n",
    "for byte_vector, labels in val_loader:\n",
    "    for i in range(len(labels)):\n",
    "        byte_vector.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output = model(byte_vector)\n",
    "\n",
    "        probabilities = torch.exp(output)\n",
    "        probab = list(probabilities.cpu().numpy()[0])\n",
    "        pred_label = probab.index(max(probab))\n",
    "        true_label = labels.cpu.numpy()[i]\n",
    "        if true_label == pred_label:\n",
    "            correct_count += 1\n",
    "        all_count += 1\n",
    "\n",
    "print(\"Number of Images Tested =\", all_count)\n",
    "print(\"\\n Model Accuracy =\", (correct_count/all_count))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
