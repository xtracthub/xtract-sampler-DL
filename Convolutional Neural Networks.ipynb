{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jupyter Notebook Version of DL\n",
    "\n",
    "The project is first developed in Jupyter Notebook for easy testing/verification but could be moved to a formal Python Script in the future (if I have time). Contrary to the Xtract-Sampler we won't be implementing any byte extraction but rather right now assume we have the data.\n",
    "***\n",
    "Training and Developing a model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from ByteVectorDataset import ByteVectorDataset\n",
    "from model import SimpleCNN\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BYTE_BLOCK_SIZE = 512"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Files/Data Processing\n",
    "\n",
    "Mostly for testing purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading files now...\n",
      "loading files done!\n"
     ]
    }
   ],
   "source": [
    "print(\"loading files now...\")\n",
    "\n",
    "with open('CDIACFileData/ByteVectors/byte_vector_dict_512B_one_gram.pkl', \"rb\") as fp1:\n",
    "    one_gram = pickle.load(fp1)\n",
    "with open('CDIACFileData/ByteVectors/byte_vector_dict_512B_two_gram.pkl', \"rb\") as fp2:\n",
    "    two_gram = pickle.load(fp2)\n",
    "\n",
    "print(\"loading files done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_path = \"CDIACFileData/labels/cdiac_naivetruth_processed.csv\"\n",
    "dataset_one_gram = ByteVectorDataset(label_path, one_gram)\n",
    "dataset_two_gram = ByteVectorDataset(label_path, two_gram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "reccomended_num_workers = 4 * torch.cuda.device_count()\n",
    "# ^ from https://discuss.pytorch.org/t/guidelines-for-assigning-num-workers-to-dataloader/813/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader_one_gram = DataLoader(dataset_one_gram, batch_size=1,\n",
    "                        shuffle=True, num_workers=reccomended_num_workers)\n",
    "dataloader_two_gram = DataLoader(dataset_two_gram, batch_size=1,\n",
    "                        shuffle=True, num_workers=reccomended_num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [tensor([[239, 187, 191,  60,  63, 120, 109, 108,  32, 118, 101, 114, 115, 105,\n",
      "         111, 110,  61,  34,  49,  46,  48,  34,  32, 101, 110,  99, 111, 100,\n",
      "         105, 110, 103,  61,  34, 117, 116, 102,  45,  56,  34,  63,  62,  13,\n",
      "          10,  60, 120,  95, 116,  97, 103, 115,  62,  13,  10,  32,  32,  60,\n",
      "          85, 115, 101, 114,  62,  13,  10,  32,  32,  32,  32,  60,  78,  97,\n",
      "         109, 101,  62,  83, 117, 108, 108, 105, 118,  97, 110,  44,  32,  75,\n",
      "         101, 118, 105, 110,  60,  47,  78,  97, 109, 101,  62,  13,  10,  32,\n",
      "          32,  32,  32,  60,  79, 114, 103,  97, 110, 105, 122,  97, 116, 105,\n",
      "         111, 110,  62,  65,  79,  77,  76,  47,  78,  79,  65,  65,  60,  47,\n",
      "          79, 114, 103,  97, 110, 105, 122,  97, 116, 105, 111, 110,  62,  13,\n",
      "          10,  32,  32,  32,  32,  60,  65, 100, 100, 114, 101, 115, 115,  62,\n",
      "          52,  51,  48,  49,  32,  82, 105,  99, 107, 101, 110,  98,  97,  99,\n",
      "         107, 101, 114,  32,  67,  97, 117, 115, 101, 119,  97, 121,  60,  47,\n",
      "          65, 100, 100, 114, 101, 115, 115,  62,  13,  10,  32,  32,  32,  32,\n",
      "          60,  80, 104, 111, 110, 101,  62,  51,  48,  53,  45,  51,  54,  49,\n",
      "          45,  52,  51,  56,  50,  60,  47,  80, 104, 111, 110, 101,  62,  13,\n",
      "          10,  32,  32,  32,  32,  60,  69, 109,  97, 105, 108,  62,  75, 101,\n",
      "         118, 105, 110,  46,  83, 117, 108, 108, 105, 118,  97, 110,  64, 110,\n",
      "         111,  97,  97,  46, 103, 111, 118,  60,  47,  69, 109,  97, 105, 108,\n",
      "          62,  32,  60,  47,  85, 115, 101, 114,  62,  13,  10,  32,  32,  60,\n",
      "          73, 110, 118, 101, 115, 116, 105, 103,  97, 116, 111, 114,  62,  13,\n",
      "          10,  32,  32,  32,  32,  60,  78,  97, 109, 101,  62,  77, 105, 108,\n",
      "         108, 101, 114, 111,  44,  32,  70, 114,  97, 110, 107,  60,  47,  78,\n",
      "          97, 109, 101,  62,  13,  10,  32,  32,  32,  32,  60,  79, 114, 103,\n",
      "          97, 110, 105, 122,  97, 116, 105, 111, 110,  62,  82,  83,  77,  65,\n",
      "          83,  47,  85, 110, 105, 118, 101, 114, 115, 105, 116, 121,  32, 111,\n",
      "         102,  32,  77, 105,  97, 109, 105,  60,  47,  79, 114, 103,  97, 110,\n",
      "         105, 122,  97, 116, 105, 111, 110,  62,  13,  10,  32,  32,  32,  32,\n",
      "          60,  65, 100, 100, 114, 101, 115, 115,  62,  52,  54,  48,  48,  32,\n",
      "          82, 105,  99, 107, 101, 110,  98,  97,  99, 107, 101, 114,  32,  67,\n",
      "          97, 117, 115, 101, 119,  97, 121,  44,  32,  77, 105,  97, 109, 105,\n",
      "          32,  70, 108,  44,  32,  51,  51,  49,  52,  57,  60,  47,  65, 100,\n",
      "         100, 114, 101, 115, 115,  62,  13,  10,  32,  32,  32,  32,  60,  80,\n",
      "         104, 111, 110, 101,  62,  51,  48,  53,  45,  52,  50,  49,  45,  52,\n",
      "          55,  48,  55,  60,  47,  80, 104, 111, 110, 101,  62,  13,  10,  32,\n",
      "          32,  32,  32,  60,  69, 109,  97, 105, 108,  62,  70,  77, 105, 108,\n",
      "         108, 101, 114, 111,  64, 114, 115, 109]], dtype=torch.uint8), tensor([3])]\n",
      "1 [tensor([[ 37,  80,  68,  70,  45,  49,  46,  53,  13,  37, 226, 227, 207, 211,\n",
      "          13,  10,  50,  49,  55,  50,  32,  48,  32, 111,  98, 106,  13,  60,\n",
      "          60,  47,  76, 105, 110, 101,  97, 114, 105, 122, 101, 100,  32,  49,\n",
      "          47,  76,  32,  49,  52,  54,  55,  54,  54,  50,  50,  47,  79,  32,\n",
      "          50,  49,  55,  52,  47,  69,  32,  52,  55,  56,  51,  51,  47,  78,\n",
      "          32,  54,  51,  47,  84,  32,  49,  52,  54,  55,  53,  54,  48,  52,\n",
      "          47,  72,  32,  91,  32,  52,  55,  53,  32,  54,  53,  55,  93,  62,\n",
      "          62,  13, 101, 110, 100, 111,  98, 106,  13,  32,  32,  32,  32,  32,\n",
      "          32,  32,  13,  10,  50,  49,  56,  48,  32,  48,  32, 111,  98, 106,\n",
      "          13,  60,  60,  47,  68, 101,  99, 111, 100, 101,  80,  97, 114, 109,\n",
      "         115,  60,  60,  47,  67, 111, 108, 117, 109, 110, 115,  32,  52,  47,\n",
      "          80, 114, 101, 100, 105,  99, 116, 111, 114,  32,  49,  50,  62,  62,\n",
      "          47,  70, 105, 108, 116, 101, 114,  47,  70, 108,  97, 116, 101,  68,\n",
      "         101,  99, 111, 100, 101,  47,  73,  68,  91,  60,  56,  54,  67,  54,\n",
      "          48,  54,  68,  68,  48,  50,  56,  52,  57,  66,  52,  70,  56,  54,\n",
      "          50,  68,  55,  68,  51,  69,  67,  68,  49,  53,  50,  66,  66,  54,\n",
      "          62,  60,  57,  65,  52,  69,  69,  54,  55,  54,  56,  55,  66,  56,\n",
      "          49,  55,  52,  53,  56,  55,  49,  56,  48,  56,  53,  54,  69,  53,\n",
      "          68,  67,  53,  52,  66,  56,  62,  93,  47,  73, 110, 100, 101, 120,\n",
      "          91,  50,  49,  55,  50,  32,  49,  55,  93,  47,  73, 110, 102, 111,\n",
      "          32,  50,  49,  55,  49,  32,  48,  32,  82,  47,  76, 101, 110, 103,\n",
      "         116, 104,  32,  53,  56,  47,  80, 114, 101, 118,  32,  49,  52,  54,\n",
      "          55,  53,  54,  48,  53,  47,  82, 111, 111, 116,  32,  50,  49,  55,\n",
      "          51,  32,  48,  32,  82,  47,  83, 105, 122, 101,  32,  50,  49,  56,\n",
      "          57,  47,  84, 121, 112, 101,  47,  88,  82, 101, 102,  47,  87,  91,\n",
      "          49,  32,  50,  32,  49,  93,  62,  62, 115, 116, 114, 101,  97, 109,\n",
      "          13,  10, 104, 222,  98,  98, 100,  16,  96,  96,  98,  96, 137,   1,\n",
      "          18, 140, 107,  65, 132,  14, 144,  96, 222,   4,  36, 184, 156,  64,\n",
      "          92,  21,  16,  43,  26,  72,  60, 218, 195, 192, 196, 200, 193,  13,\n",
      "         100,  49,  48,  48, 226,  38, 254, 255, 140, 249,   5,  16,  96,   0,\n",
      "          13,  28,   8,   0,  13,  10, 101, 110, 100, 115, 116, 114, 101,  97,\n",
      "         109,  13, 101, 110, 100, 111,  98, 106,  13, 115, 116,  97, 114, 116,\n",
      "         120, 114, 101, 102,  13,  10,  48,  13,  10,  37,  37,  69,  79,  70,\n",
      "          13,  10,  32,  32,  32,  32,  32,  32,  32,  32,  32,  13,  10,  50,\n",
      "          49,  56,  56,  32,  48,  32, 111,  98, 106,  13,  60,  60,  47,  67,\n",
      "          32,  56,  49,  48,  47,  70, 105, 108, 116, 101, 114,  47,  70, 108,\n",
      "          97, 116, 101,  68, 101,  99, 111, 100]], dtype=torch.uint8), tensor([1])]\n",
      "2 [tensor([[ 37,  80,  68,  70,  45,  49,  46,  51,  10,  37, 196, 229, 242, 229,\n",
      "         235, 167, 243, 160, 208, 196, 198,  10,  52,  32,  48,  32, 111,  98,\n",
      "         106,  10,  60,  60,  32,  47,  76, 101, 110, 103, 116, 104,  32,  53,\n",
      "          32,  48,  32,  82,  32,  47,  70, 105, 108, 116, 101, 114,  32,  47,\n",
      "          70, 108,  97, 116, 101,  68, 101,  99, 111, 100, 101,  32,  62,  62,\n",
      "          10, 115, 116, 114, 101,  97, 109,  10, 120,   1, 221,  93, 219, 114,\n",
      "          28,  71, 114, 125, 239, 175, 168,  39, 199,  32, 130, 108, 117, 245,\n",
      "         189, 215,  47, 230, 202,  92,  91, 218, 213, 202, 150,  16, 187, 118,\n",
      "         120,  29,  12,  94, 150, 196,  90, 194,  12, 185,  52, 100, 201,  31,\n",
      "         235, 111, 241, 201, 234,  58, 153,  53, 152, 110, 118, 247, 128,  36,\n",
      "          96, 135,  34,  52, 152, 131, 169, 194, 116, 158, 202, 107, 101,  21,\n",
      "         223, 185, 127, 118, 239,  92, 225, 186, 161, 116, 215, 174, 238, 135,\n",
      "         118, 252, 249, 199, 248, 243, 227, 182, 108, 218, 222, 253, 136, 143,\n",
      "         232, 143,  87, 250, 249,  63, 186, 189, 107, 106, 215,  85, 189, 187,\n",
      "         206, 154, 166, 203, 135, 161, 245, 225, 237, 143, 206, 222, 182,  24,\n",
      "          46, 159, 146, 215,  43, 253, 188, 147, 193,  95, 124, 249, 222, 187,\n",
      "         151, 239, 157,  15, 255, 189, 127,  25, 127, 155,  93, 143, 195, 187,\n",
      "         178,  75, 103,  11, 111, 219, 188,  40, 171, 186, 230, 156, 250,  46,\n",
      "         153, 249, 181,  61,  20, 102, 186, 203,  67,  37,  79,  81, 245, 217,\n",
      "         202, 135, 106, 134, 188, 170, 154,  65, 228,  82, 230, 109,  91, 123,\n",
      "          72, 182, 105, 154, 220, 247,  85, 171,  88, 152, 140,  88, 144, 144,\n",
      "         142, 138, 114, 210, 247,  54,  75,  42, 178,  34, 111, 135, 190, 168,\n",
      "         134,  50, 211, 159, 156, 253,  36, 162, 156, 152, 224, 228, 107, 136,\n",
      "          24, 237, 171, 249, 188, 235, 170,  90, 190, 154, 141,  29, 177, 145,\n",
      "          58,  67, 245, 193,  94,  79, 124, 246, 218, 181,  69,  94, 150, 109,\n",
      "         211, 102,  93, 165, 227, 137, 185, 199, 126, 232, 203, 188, 244, 141,\n",
      "         252, 113,  78, 153, 130, 160, 146, 176, 142, 191, 206,  94,  99, 217,\n",
      "         201, 127, 242, 104,  77, 157, 151,  67, 165, 194, 156,  18, 112, 250,\n",
      "         100,  50, 185, 207, 171,  50, 172, 154, 113, 108, 150,  98, 248, 131,\n",
      "         167,  51,  38,  79, 198, 207,  98, 153, 155, 184,  20,  76, 169,  20,\n",
      "          80, 158, 109, 152, 122,  54,   1, 147, 103, 211,   9,  48, 107,  92,\n",
      "         178, 217, 221, 245,  16,  95, 112, 212,  67, 200,  94,  20, 151, 111,\n",
      "          71, 253, 155, 209, 195, 214, 231, 222, 119, 248, 214,  93,  89, 230,\n",
      "         125, 215,  15, 248,  74, 190, 174, 115, 188, 133,   6,  70,  12, 207,\n",
      "         105,  88,   1,   6, 138, 202, 227,  15, 216,  88, 195, 174,  18, 212,\n",
      "         102,  76, 150, 111, 166,  92, 190, 115,  30, 203, 182,  43,  97, 128,\n",
      "           4, 211,  55,  45,  20, 189, 232,  10]], dtype=torch.uint8), tensor([1])]\n",
      "3 [tensor([[ 37,  80,  68,  70,  45,  49,  46,  51,  10,  37, 196, 229, 242, 229,\n",
      "         235, 167, 243, 160, 208, 196, 198,  10,  52,  32,  48,  32, 111,  98,\n",
      "         106,  10,  60,  60,  32,  47,  76, 101, 110, 103, 116, 104,  32,  53,\n",
      "          32,  48,  32,  82,  32,  47,  70, 105, 108, 116, 101, 114,  32,  47,\n",
      "          70, 108,  97, 116, 101,  68, 101,  99, 111, 100, 101,  32,  62,  62,\n",
      "          10, 115, 116, 114, 101,  97, 109,  10, 120,   1, 181, 155,  93, 111,\n",
      "         221,  54,  18, 134, 239, 245,  43, 120, 181,  56,   6,  26,  69,  36,\n",
      "         245, 217, 171, 117, 210,   5, 154,   2, 109, 210, 141, 145, 189, 216,\n",
      "          22, 133, 227,  56, 109, 183,  73, 156, 198,  78, 187, 253, 247, 251,\n",
      "          12, 135, 250, 224,  57,  18, 125,  18, 123,  17,  68, 210, 209, 199,\n",
      "         144, 156, 121, 231, 157, 225, 144, 254, 221, 124, 111, 126,  55, 214,\n",
      "         150, 173, 139, 199, 166, 179, 101, 215, 154, 222, 246, 114, 250, 112,\n",
      "         105, 254, 101, 222, 153, 135, 143, 175, 173, 185, 184,  54,  85, 248,\n",
      "         119, 125, 193,  55,  85, 233, 106, 253,  45,  23,  67,  85,  54, 221,\n",
      "          48, 180, 166, 107, 171, 210,  23,  23, 111, 205, 163,  51,  94, 169,\n",
      "         170, 218, 155, 179,  11,  83, 219, 240, 106,  60, 157, 189,  53,  15,\n",
      "         207, 206, 172, 177, 230, 236, 181, 249, 183, 217,  61, 249, 246, 196,\n",
      "          60, 176, 149, 217,  61, 229, 220, 155, 221, 115,  78, 157, 217, 153,\n",
      "         143, 156, 219,  98, 247,  78,  78, 102, 247,  74,  79, 151, 156,  26,\n",
      "         179, 251, 192, 201, 153, 221, 159, 156,   6, 179,  59, 215, 155, 127,\n",
      "         233, 201,  60, 230, 140,  28, 196, 253, 104, 206, 190,  49, 255,  56,\n",
      "          11, 163,  76, 123, 108, 123,  95, 250, 158,  33, 118,  77,  95, 246,\n",
      "         109, 236, 178, 235,  66,  71, 227,  41, 233, 232, 206, 157, 152, 179,\n",
      "         255, 108,   9, 235,  24, 171,  75, 135, 159,  25, 244, 206, 228, 100,\n",
      "          13, 101, 215,  87, 195, 129,  42, 135, 254, 118,  85, 190,  66,  19,\n",
      "         214, 236, 110,  78,  76,  29, 180, 194, 245, 117, 184, 115, 121,  82,\n",
      "          76, 247, 105,  28, 125, 162,  65, 111, 118, 168, 147, 251, 239, 175,\n",
      "         244,  23, 223, 109, 107, 204,  53, 109,  89, 183,  77, 147, 116, 236,\n",
      "          51,   7,  57, 227, 165,   6, 103, 125, 212, 254, 157, 133, 249, 174,\n",
      "         116, 163,  41,  65, 159, 181, 195, 237,  42, 251,  10, 149, 161,   8,\n",
      "         134, 142,  82, 244,  26, 149,   5, 213,  20, 211, 253,  47, 115, 138,\n",
      "         177, 158, 182, 188, 183, 166,  11, 237,  27,  69, 127,  50, 152,  66,\n",
      "         161, 132, 147,   9, 230, 179, 230, 247, 174, 236, 173, 173, 239,  73,\n",
      "          88,  83,  54, 253, 208, 165, 194,  68,  51, 213,  33, 152, 210,  62,\n",
      "         226, 151, 167, 167,  63, 157,  24, 156,  12, 224, 115, 172, 194, 209,\n",
      "         134, 163,  15, 199, 229, 211,  62, 220, 225,  40, 248,  41, 214,  61,\n",
      "         110, 232, 203, 161, 247,  62, 237,  76]], dtype=torch.uint8), tensor([1])]\n"
     ]
    }
   ],
   "source": [
    "for i_batch, sample_batched in enumerate(dataloader_one_gram):\n",
    "    print(i_batch, sample_batched)\n",
    "    # observe 4th batch and stop.\n",
    "    if i_batch == 3:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From here on out we will just be using one grams but the two grams process is identical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11474\n",
      "2869\n"
     ]
    }
   ],
   "source": [
    "TRAIN_TEST_SPLIT = .8 # 80% for training 20% for testing\n",
    "train_set_size = int(TRAIN_TEST_SPLIT * len(dataset_one_gram))\n",
    "val_set_size = len(dataset_one_gram) - train_set_size\n",
    "train_set, val_set = torch.utils.data.random_split(dataset_one_gram, [train_set_size, val_set_size])\n",
    "print(len(train_set))\n",
    "print(len(val_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_set, batch_size=32,\n",
    "                        shuffle=True, num_workers=reccomended_num_workers)\n",
    "val_loader = DataLoader(val_set, batch_size=32,\n",
    "                        shuffle=True, num_workers=reccomended_num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "torch.Size([32, 512])\n",
      "tensor([2, 1, 1, 3, 2, 1, 2, 1, 3, 1, 1, 1, 3, 4, 0, 2, 1, 2, 2, 1, 2, 3, 5, 2,\n",
      "        1, 2, 3, 1, 1, 1, 1, 2])\n"
     ]
    }
   ],
   "source": [
    "dataiter = iter(train_loader)\n",
    "images, labels = dataiter.next()\n",
    "print(type(images))\n",
    "print(images.shape)\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's use 4 GPUs!\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = SimpleCNN(BYTE_BLOCK_SIZE)\n",
    "if torch.cuda.device_count() > 1:\n",
    "  print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "  model = nn.DataParallel(model)\n",
    "model.to(device)\n",
    "    \n",
    "loss_function = nn.NLLLoss() # This is a convex loss function\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=.03) # From my CS361 class SGD is shown to do well on convex functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Caught RuntimeError in replica 0 on device 0.\nOriginal Traceback (most recent call last):\n  File \"/home/cc/anaconda3/lib/python3.8/site-packages/torch/nn/parallel/parallel_apply.py\", line 61, in _worker\n    output = module(*input, **kwargs)\n  File \"/home/cc/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1051, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/cc/xtract-sampler-DL/model.py\", line 20, in forward\n    out = self.l1(x)\n  File \"/home/cc/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1051, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/cc/anaconda3/lib/python3.8/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/home/cc/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1051, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/cc/anaconda3/lib/python3.8/site-packages/torch/nn/modules/conv.py\", line 298, in forward\n    return self._conv_forward(input, self.weight, self.bias)\n  File \"/home/cc/anaconda3/lib/python3.8/site-packages/torch/nn/modules/conv.py\", line 294, in _conv_forward\n    return F.conv1d(input, weight, bias, self.stride,\nRuntimeError: Expected 3-dimensional input for 3-dimensional weight [256, 512, 8], but got 2-dimensional input of size [8, 512] instead\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-44f0a24c938e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;31m#Training Pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbyte_vector\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    166\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m             \u001b[0mreplicas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    169\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\u001b[0m in \u001b[0;36mparallel_apply\u001b[0;34m(self, replicas, inputs, kwargs)\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/parallel/parallel_apply.py\u001b[0m in \u001b[0;36mparallel_apply\u001b[0;34m(modules, inputs, kwargs_tup, devices)\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExceptionWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m             \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m         \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/_utils.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    423\u001b[0m             \u001b[0;31m# have message field\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 425\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Caught RuntimeError in replica 0 on device 0.\nOriginal Traceback (most recent call last):\n  File \"/home/cc/anaconda3/lib/python3.8/site-packages/torch/nn/parallel/parallel_apply.py\", line 61, in _worker\n    output = module(*input, **kwargs)\n  File \"/home/cc/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1051, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/cc/xtract-sampler-DL/model.py\", line 20, in forward\n    out = self.l1(x)\n  File \"/home/cc/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1051, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/cc/anaconda3/lib/python3.8/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/home/cc/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1051, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/cc/anaconda3/lib/python3.8/site-packages/torch/nn/modules/conv.py\", line 298, in forward\n    return self._conv_forward(input, self.weight, self.bias)\n  File \"/home/cc/anaconda3/lib/python3.8/site-packages/torch/nn/modules/conv.py\", line 294, in _conv_forward\n    return F.conv1d(input, weight, bias, self.stride,\nRuntimeError: Expected 3-dimensional input for 3-dimensional weight [256, 512, 8], but got 2-dimensional input of size [8, 512] instead\n"
     ]
    }
   ],
   "source": [
    "time0 = time()\n",
    "epochs = 100\n",
    "for epoch in range(epochs):\n",
    "    running_loss = 0\n",
    "    for byte_vector, labels in train_loader:\n",
    "        byte_vector = byte_vector.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        #Training Pass\n",
    "        optimizer.zero_grad()\n",
    "        output = model(byte_vector).to(device)\n",
    "        loss = loss_function(output, labels)\n",
    "        \n",
    "        #backpropagation\n",
    "        loss.backward()\n",
    "        \n",
    "        #optimization\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    else:\n",
    "        print(\"Epoch {} - Training loss: {}\".format(e, running_loss/len(train_loader)))\n",
    "\n",
    "\n",
    "print(\"\\nTraining Time (in minutes) = \", (time()-time0)/60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_count, all_count = 0\n",
    "for byte_vector, labels in val_loader:\n",
    "    for i in range(len(labels)):\n",
    "        byte_vector.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output = model(byte_vector)\n",
    "\n",
    "        probabilities = torch.exp(output)\n",
    "        probab = list(probabilities.cpu().numpy()[0])\n",
    "        pred_label = probab.index(max(probab))\n",
    "        true_label = labels.cpu.numpy()[i]\n",
    "        if true_label == pred_label:\n",
    "            correct_count += 1\n",
    "        all_count += 1\n",
    "\n",
    "print(\"Number of Images Tested =\", all_count)\n",
    "print(\"\\n Model Accuracy =\", (correct_count/all_count))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
